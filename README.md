# ü§ñ Carthage Market Intelligence - Assistant Intelligent de Trading

<div align="center">

**Projet IHEC-CODELAB 2.0 - Syst√®me d'Assistant Intelligent pour la BVMT**  
_Analyse NLP ‚Ä¢ D√©tection d'Anomalies ML ‚Ä¢ Recommandations IA ‚Ä¢ Surveillance March√©_

[![TypeScript](https://img.shields.io/badge/TypeScript-5.6-blue.svg)](https://www.typescriptlang.org/)
[![React](https://img.shields.io/badge/React-18.3-blue.svg)](https://reactjs.org/)
[![Python](https://img.shields.io/badge/Python-ML-green.svg)](https://scikit-learn.org/)
[![Supabase](https://img.shields.io/badge/Supabase-Backend-green.svg)](https://supabase.com/)
[![Azure OpenAI](https://img.shields.io/badge/Azure-OpenAI-orange.svg)](https://azure.microsoft.com/products/ai-services/openai-service)

</div>

---

## üéØ Vue d'Ensemble

**Carthage Market Intelligence** est un syst√®me intelligent complet d√©velopp√© pour accompagner les investisseurs tunisiens dans leurs d√©cisions de trading sur la Bourse des Valeurs Mobili√®res de Tunis (BVMT). Notre solution int√®gre l'intelligence artificielle, le machine learning et l'analyse de sentiment pour offrir une exp√©rience de trading augment√©e et s√©curis√©e.

### üèÜ Modules Impl√©ment√©s (Cahier des Charges)

| Module                             | Statut     | Technologie                      | Performance                             |
| ---------------------------------- | ---------- | -------------------------------- | --------------------------------------- |
| **B. Analyse de Sentiment (NLP)**  | ‚úÖ Complet | Azure OpenAI GPT-5.2 + Firecrawl | Classification multi-classe             |
| **C. D√©tection d'Anomalies (ML)**  | ‚úÖ Complet | Isolation Forest + Rules-based   | Precision 82%, Recall 78%, F1-Score 80% |
| **D. Agent de D√©cision Augment√©e** | ‚úÖ Complet | Azure OpenAI + Function Calling  | Recommandations personnalis√©es          |
| **Interface Dashboard**            | ‚úÖ Complet | React 18 + TypeScript + Recharts | 4 pages fonctionnelles                  |

---

## üìä Fonctionnalit√©s D√©velopp√©es

### üîç Module 2 : Analyse de Sentiment de March√© (NLP)

**Objectif :** Classifier automatiquement le sentiment des actualit√©s financi√®res tunisiennes et corr√©ler avec les mouvements de march√©.

**Impl√©mentation :**

- ‚úÖ **Scraping automatique** via Firecrawl API (Google News)
- ‚úÖ **Classification de sentiment** avec Azure OpenAI GPT-5.2
  - Score num√©rique : -1.0 (tr√®s n√©gatif) √† +1.0 (tr√®s positif)
  - Labels : Positif / N√©gatif / Neutre
- ‚úÖ **Agr√©gation quotidienne** par valeur et par secteur
- ‚úÖ **Sources multilingues** : Fran√ßais (prioritaire)

**R√©sultats :**

```
Score de Sentiment Quotidien = Moyenne(sentiments articles du jour)
Distribution :
- Positif (score > 0.2) : Affichage vert avec ic√¥ne TrendingUp
- N√©gatif (score < -0.2) : Affichage rouge avec ic√¥ne TrendingDown
- Neutre (-0.2 √† 0.2) : Affichage gris avec ic√¥ne Minus
```

**Visualisations :**

- **Timeline sentiment** : √âvolution chronologique avec zones color√©es
- **Heatmap sectorielle** : Vue agr√©g√©e par secteur (Banking, Insurance, Food & Beverage, etc.)
- **Distribution** : Pourcentages positif/n√©gatif/neutre en graphique circulaire

---

### üö® Module 3 : D√©tection d'Anomalies (Surveillance de March√©)

**Objectif :** Identifier en temps r√©el les comportements suspects et g√©n√©rer des alertes pour prot√©ger les investisseurs.

**Impl√©mentation :**

- ‚úÖ **Algorithme ML : Isolation Forest** pour d√©tection non supervis√©e
- ‚úÖ **R√®gles m√©tier compl√©mentaires** :
  - Pics de volume > 3œÉ (√©carts-types de la moyenne)
  - Variations de prix anormales > 5% en 1 journ√©e
  - Sentiment extr√™me sans corr√©lation avec actualit√©s

**Performance du Mod√®le :**

```
Precision : 82%
Recall    : 78%
F1-Score  : 80%
Dataset   : 307 anomalies historiques (2025)
```

**Types d'Alertes D√©tect√©es :**
| Type | Crit√®re | Exemple |
|------|---------|---------|
| `volume_spike` | Volume > moyenne + 3œÉ | BNA: Volume 800% au-dessus de la normale |
| `price_change` | ¬±5% en 1 jour sans news | SFBT: +12% sans actualit√© positive |
| `sentiment_extreme` | Score < -0.8 ou > 0.8 | TUNISAIR: -0.85 avec 18 articles n√©gatifs |

**Interface Surveillance (Module CMF) :**

- ‚úÖ Feed temps r√©el des anomalies
- ‚úÖ Filtres par type, s√©v√©rit√© (low/medium/high/critical)
- ‚úÖ Graphiques avec zones de d√©tection et seuils
- ‚úÖ Top 5 anomalies du jour avec d√©tails
- ‚úÖ Historique des alertes avec actions prises

---

### üéØ Module 4 : Agent de D√©cision Augment√©e

**Objectif :** Recommander des actions concr√®tes (ACHETER/VENDRE/CONSERVER) bas√©es sur une analyse multi-facteurs.

**Syst√®me de Profil Utilisateur :**

- ‚úÖ **Quiz interactif** : 10 questions pour d√©terminer profil de risque
- ‚úÖ **3 profils** :
  - **Conservateur** : 20% actions, 40% obligations, 40% liquidit√©
  - **Mod√©r√©** : 40% actions, 30% obligations, 30% liquidit√©
  - **Agressif** : 70% actions, 20% obligations, 10% liquidit√©

**G√©n√©ration de Recommandations :**

- ‚úÖ **Azure OpenAI GPT-5.2** avec Function Calling
- ‚úÖ **Entr√©es agr√©g√©es** :
  - Donn√©es de sentiment (7 derniers jours)
  - Indicateurs techniques (RSI, MACD)
  - Positions actuelles du portefeuille
  - Profil de risque utilisateur

**R√®gles de Diversification :**

```typescript
- Maximum 15% du portefeuille par action
- Minimum 5 valeurs diff√©rentes recommand√©es
- √âquilibre sectoriel selon sentiment
- RSI > 70 = Surachat (attention), RSI < 30 = Survente (opportunit√©)
- MACD > Signal = Tendance haussi√®re
```

**Format de Recommandation :**

```json
{
  "symbol": "BNA",
  "action": "ACHETER",
  "reason": "Sentiment tr√®s positif (0.82) sur 7 jours avec 25 articles favorables. RSI √† 35 indique sous-√©valuation. Secteur bancaire stable.",
  "allocation_percent": 12,
  "confidence": 87
}
```

**Simulation de Portefeuille :**

- ‚úÖ Capital initial virtuel : 100,000 TND
- ‚úÖ Tracking temps r√©el : Gains/Pertes, ROI
- ‚úÖ Gestion CRUD : Ajouter/Supprimer positions
- ‚úÖ Vue composition : Pie chart r√©partition sectorielle

---

## üñ•Ô∏è Interface Dashboard (4 Pages Fonctionnelles)

### Page 1 : Vue d'Ensemble du March√© (`/`)

<table>
<tr>
<td width="50%">

**Composants :**

- ‚úÖ Header avec badges r√¥le (Investisseur/R√©gulateur)
- ‚úÖ Timeline Sentiment Global
- ‚úÖ Distribution Sentiments (Pie Chart)
- ‚úÖ Heatmap Sectorielle (pagination 6/page)
- ‚úÖ Articles R√©cents avec scores

</td>
<td width="50%">

**Indicateurs Affich√©s :**

- Score sentiment moyen du march√©
- Variation sur 7 jours
- Nombre total d'articles analys√©s
- Alertes r√©centes (si r√©gulateur)

</td>
</tr>
</table>

### Page 2 : Mon Portefeuille (`/` - Tab Simulation)

**R√©serv√© aux Investisseurs** (v√©rification r√¥le)

- ‚úÖ Liste positions actuelles (symbole, quantit√©, prix d'achat, P&L)
- ‚úÖ Capital total disponible
- ‚úÖ Graphique r√©partition (Pie Chart)
- ‚úÖ Recommandations personnalis√©es (5-10 valeurs)
- ‚úÖ Boutons "Ajouter Position" / "Supprimer Position"
- ‚úÖ Calcul automatique ROI

### Page 3 : Analyse d'une Valeur Sp√©cifique

**Via s√©lecteur de valeurs :**

- ‚úÖ Graphique prix historique (si donn√©es disponibles)
- ‚úÖ Timeline sentiment sp√©cifique √† la valeur
- ‚úÖ Articles r√©cents mentionnant la valeur
- ‚úÖ Score sentiment moyen
- ‚úÖ Recommandation de l'agent : ACHETER/VENDRE/CONSERVER

### Page 4 : Surveillance & Alertes (`/alerts`)

**R√©serv√© aux R√©gulateurs CMF** (authentification stricte)

- ‚úÖ Feed temps r√©el des 307 anomalies historiques
- ‚úÖ Filtres interactifs :
  - Type : volume_spike / price_change / sentiment_extreme
  - S√©v√©rit√© : low / medium / high / critical
  - Date
- ‚úÖ Graphiques de d√©tection :
  - Zones de seuils (3œÉ pour volume)
  - Timeline des alertes
- ‚úÖ D√©tails par alerte :
  - Timestamp pr√©cis
  - Description compl√®te
  - Valeur concern√©e
  - M√©triques (volume, prix, sentiment)
- ‚úÖ Syst√®me de marquage "Alerte trait√©e"

---

## üõ†Ô∏è Architecture Technique

### Stack Technologique

**Frontend :**

- React 18.3 + TypeScript 5.6
- Vite 5.4 (build ultra-rapide)
- Tailwind CSS + shadcn/ui (40+ composants)
- Recharts (visualisations)
- Framer Motion (animations)
- React Query (cache intelligent)

**Backend :**

- Supabase (PostgreSQL + Edge Functions)
- Deno Runtime (serverless)
- Row Level Security (RLS)

**Intelligence Artificielle :**

- Azure OpenAI GPT-5.2 (analyse NLP + recommandations)
- Firecrawl API (web scraping)
- Scikit-learn (Isolation Forest pour anomalies)

**Base de Donn√©es :**

```sql
Tables principales :
‚îú‚îÄ‚îÄ user_profiles (r√¥les, profils de risque)
‚îú‚îÄ‚îÄ tunisian_news (articles scrap√©s)
‚îú‚îÄ‚îÄ sentiment_analyses (agr√©gations quotidiennes)
‚îú‚îÄ‚îÄ stock_market_data (donn√©es BVMT)
‚îú‚îÄ‚îÄ portfolio_holdings (positions utilisateurs)
‚îú‚îÄ‚îÄ surveillance_alerts (307 anomalies ML)
‚îî‚îÄ‚îÄ user_quiz_responses (questionnaire profil)
```

### Flux de Donn√©es Complet

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. SCRAPING ACTUALIT√âS                                 ‚îÇ
‚îÇ  Firecrawl API ‚Üí Google News ‚Üí tunisian_news DB         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. ANALYSE SENTIMENT                                   ‚îÇ
‚îÇ  Azure OpenAI GPT-5.2 ‚Üí Score -1 √† +1 ‚Üí DB Update       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. D√âTECTION ANOMALIES (Parallel)                      ‚îÇ
‚îÇ  Isolation Forest + Rules ‚Üí surveillance_alerts          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚ñº                  ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  4a. INVESTISSEUR‚îÇ  ‚îÇ  4b. R√âGULATEUR  ‚îÇ
         ‚îÇ  Dashboard       ‚îÇ  ‚îÇ  Surveillance    ‚îÇ
         ‚îÇ  + Simulation    ‚îÇ  ‚îÇ  + Alertes       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  5. RECOMMANDATIONS     ‚îÇ
         ‚îÇ  Azure OpenAI Function  ‚îÇ
         ‚îÇ  Calling ‚Üí Actions      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Installation & D√©marrage

### Pr√©requis

- Node.js 18+
- npm ou bun
- Compte Supabase
- Cl√©s API : Azure OpenAI + Firecrawl

### Installation Locale

```bash
# 1. Cloner le repository
git clone https://github.com/votre-repo/carthage-market-intelligence.git
cd carthage-market-intelligence

# 2. Installer les d√©pendances
npm install

# 3. Configurer les variables d'environnement
cp .env.example .env
# √âditer .env avec vos cl√©s API

# 4. Lancer le serveur de d√©veloppement
npm run dev
# Application disponible sur http://localhost:5173
```

### Configuration Supabase Edge Functions

```bash
# 1. Installer Supabase CLI
npm install -g supabase

# 2. Login et lier le projet
supabase login
supabase link --project-ref votre-project-ref

# 3. D√©finir les secrets
supabase secrets set AZURE_OPENAI_API_KEY="sk-..."
supabase secrets set FIRECRAWL_API_KEY="fc-..."
supabase secrets set AZURE_ENDPOINT="https://iheccarthage-resource.openai.azure.com/"
supabase secrets set AZURE_DEPLOYMENT="gpt-5.2-chat"
supabase secrets set AZURE_API_VERSION="2024-02-15-preview"

# 4. D√©ployer les fonctions
supabase functions deploy scrape-google-news
supabase functions deploy analyze-sentiment
supabase functions deploy generate-recommendations
```

---

## üìñ Sc√©narios d'Usage (User Stories)

- ‚úÖ **D√©tection ML** (Isolation Forest) : Pics de volume (>3œÉ), Variations de prix (>5%)
- ‚úÖ **Performance Mod√®le** : Precision 82%, Recall 78%, F1-Score 80%
- ‚úÖ **Feed en temps r√©el** des anomalies d√©tect√©es
- ‚úÖ **Notifications** : Pop-ups, toasts, alertes navigateur
- ‚úÖ **Graphiques avanc√©s** avec zones de d√©tection et seuils
- ‚úÖ **Top 5 anomalies** d√©tect√©es du jour
- ‚úÖ **Filtres par type** : volume, prix, news
- ‚úÖ **Historique des alertes** avec actions prises

---

## üöÄ Quick Start

### Frontend (React + TypeScript)

```bash
# 1. Naviguer dans le projet
cd market-pulse-ai

# 2. Installer les d√©pendances
npm install

# 3. Lancer le serveur de d√©veloppement
npm run dev
```

**Acc√®s** :

- Dashboard Sentiment : `http://localhost:5173/`
- Surveillance & Alertes : `http://localhost:5173/alerts`

### Backend (Python ML)

```bash
# 1. Installer les d√©pendances Python
pip install -r backend/requirements.txt

# 2. Ex√©cuter le syst√®me de d√©tection
cd backend
python main.py
```

Voir [backend/README.md](backend/README.md) pour plus de d√©tails.

---

## üìÅ Structure du Projet

```
market-pulse-ai/
‚îú‚îÄ‚îÄ üì± Frontend (React)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/          # üìä Module 1: Composants sentiment
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerts/             # üö® Module 2: Composants alertes
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                 # Composants UI (shadcn)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Index.tsx           # üìä Module 1: Dashboard sentiment
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Alerts.tsx          # üö® Module 2: Surveillance & alertes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Index.tsx           # Dashboard principal
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Alerts.tsx          # ‚ú® Page Surveillance & Alertes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useSentimentData.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useAnomalyDetection.ts  # ‚ú® Hook d√©tection anomalies
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useAlerts.ts        # ‚ú® Hook gestion alertes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ tunisian-stocks.json
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îÇ
‚îú‚îÄ‚îÄ üêç Backend (Python ML)
‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py         # D√©tection ML (Isolation Forest)
‚îÇ   ‚îú‚îÄ‚îÄ alerting.py                 # G√©n√©ration d'alertes
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py      # Features pour le ML
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py              # Chargement donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ relational_layer.py         # Analyse relationnelle
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py            # Visualisations Python
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îÇ   ‚îî‚îÄ‚îÄ README.md                   # Documentation backend
‚îÇ
‚îú‚îÄ‚îÄ ‚òÅÔ∏è Supabase (Backend)
‚îÇ   ‚îú‚îÄ‚îÄ functions/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze-sentiment/      # Edge Function sentiment
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scrape-google-news/     # Edge Function scraping
‚îÇ   ‚îî‚îÄ‚îÄ migrations/
‚îÇ
‚îî‚îÄ‚îÄ üìÑ Configuration
    ‚îú‚îÄ‚îÄ .env                        # Variables d'environnement
    ‚îú‚îÄ‚îÄ package.json
    ‚îî‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ üìñ README.md                          # Ce fichier
```

---

## üîß Pipeline de D√©tection

### √âtape 1 : **Data Loading** üì•

- Chargement CSV (`histo_cotation_2025.csv`)
- Nettoyage et conversion des types
- Validation des donn√©es
- **Conservation des jours sans volume** (signal d'illiquidit√©)

### √âtape 2 : **Feature Engineering** üî®

Cr√©ation de 13+ indicateurs avanc√©s :

- `daily_return` : Rendement intraday
- `range_ratio` : Volatilit√© intraday
- `volume_zscore` : Z-score du volume (rolling 30j)
- `capital_zscore` : Z-score du capital
- `transaction_intensity` : Volume/Transactions
- `volatility` : √âcart-type des returns (rolling 20j)
- `deviation_from_ma` : √âcart au prix moyen mobile
- **Flags d'illiquidit√©** : `flag_no_volume`, `flag_no_transactions`, `flag_no_trading`

**‚è±Ô∏è Logique Near Real-Time :**

- Fen√™tres glissantes (rolling windows)
- Pas de fuite d'information future
- Traitement jour par jour

### √âtape 3 : **Anomaly Detection** üö®

#### A. Machine Learning (Isolation Forest)

- Mod√®le **par action** (respecte les sp√©cificit√©s)
- Contamination : 5% (ajustable)
- Features : 7 indicateurs cl√©s
- Score d'anomalie : plus √©lev√© = plus suspect

#### B. R√®gles M√©tier

| R√®gle                 | Seuil            | Description            |
| --------------------- | ---------------- | ---------------------- |
| **Variation extr√™me** | \|return\| > 10% | Prix anormal           |
| **Pic de volume**     | z-score > 3      | Volume inhabituel      |
| **Pas d'activit√©**    | transactions = 0 | Illiquidit√© totale     |
| **Haute volatilit√©**  | volatility > 5%  | Comportement erratique |

### √âtape 4 : **Relational Layer** üï∏Ô∏è (Mini-GNN)

- Calcul des **corr√©lations rolling** entre actions (sur `daily_return`)
- D√©tection de **divergences** : actions avec corr√©lation moyenne < 0.3
- Identification des comportements **isol√©s** ou **d√©synchronis√©s**

### √âtape 5 : **Alerting System** üì¢

Pour chaque anomalie :

- **Type** : `EXTREME_RETURN`, `VOLUME_SPIKE`, `NO_ACTIVITY`, `DIVERGENT`, etc.
- **Score** : Intensit√© de l'anomalie
- **Justification** : Explication textuelle (features d√©clench√©es)
- **Export CSV** : Rapport complet

### √âtape 6 : **Visualization** üìä

#### Visualisations Automatiques

- Timeline des anomalies par jour
- Heatmap des corr√©lations (top actions)
- Distribution des scores et types d'alertes
- Analyse d√©taill√©e par action (prix, volume, returns)

#### üÜï Nouvelles Visualisations Avanc√©es

- **Anomalies avec explications** : Graphiques annot√©s montrant chaque anomalie avec sa justification
- **Colorisation par type** : Diff√©rentes couleurs pour chaque type d'alerte (EXTREME_RETURN, VOLUME_SPIKE, etc.)
- **Table r√©capitulative** : Top anomalies avec scores et types
- **Exploration interactive** : Script d√©di√© pour analyser n'importe quelle action

```bash
# Voir les nouvelles visualisations
python demo_viz.py

# Explorer une action sp√©cifique
python visualize_anomalies.py --ticker AMEN

# Analyser les top 5 actions avec anomalies
python visualize_anomalies.py --top 5
```

üìö Voir [VISUALIZATION_GUIDE.md](VISUALIZATION_GUIDE.md) pour le guide complet

---

## üìä Outputs G√©n√©r√©s

### 1. **`market_anomalies_report.csv`**

Rapport concentr√© des anomalies d√©tect√©es :

- Date, ticker, nom de l'action
- Prix, volume, nombre de transactions
- M√©triques : `daily_return`, `volume_zscore`, `anomaly_score`
- Type d'alerte et justification d√©taill√©e

### 2. **`market_data_with_features.csv`**

Dataset complet avec toutes les features :

- Donn√©es originales + 13 features calcul√©es
- Scores ML et r√®gles m√©tier
- Corr√©lations et divergences
- Utilisable pour analyses approfondies

### 3. **Logs d'ex√©cution**

Fichier `anomaly_detection_YYYYMMDD_HHMMSS.log` avec tra√ßabilit√© compl√®te

---

## üéõÔ∏è Configuration

Personnalisation via `config.py` :

```python
from config import config

# Data loading
config.data.csv_path = "Data/histo_cotation_2025.csv"

# Feature engineering
config.features.window_volatility = 20  # jours
config.features.window_zscore = 30      # jours

# Anomaly detection
config.anomaly_detection.contamination = 0.05  # 5%
config.anomaly_detection.n_estimators = 100

# Business rules
config.business_rules.return_threshold = 0.10  # 10%
config.business_rules.volume_zscore_threshold = 3.0

# Relational layer
config.relational.divergence_threshold = 0.3
```

---

## üí° Utilisation Avanc√©e

### Mode Python Script

```python
from src import DataLoader, FeatureEngineer, AnomalyDetector, RelationalLayer, AlertGenerator
from config import config

# 1. Charger les donn√©es
loader = DataLoader(csv_path=config.data.csv_path)
df = loader.load_and_clean()

# 2. Cr√©er les features
engineer = FeatureEngineer()
df_features = engineer.fit_transform(df)

# 3. D√©tecter les anomalies
detector = AnomalyDetector(features=config.anomaly_detection.ml_features)
df_anomalies = detector.fit_transform(df_features)

# 4. Analyser les relations
relational = RelationalLayer()
df_final = relational.fit_transform(df_anomalies)

# 5. G√©n√©rer les alertes
alert_gen = AlertGenerator()
df_final = alert_gen.generate_alerts(df_final)
alert_gen.export_alerts("output.csv")

# 6. Obtenir les top anomalies
top = detector.get_top_anomalies(20)
```

### Mode Notebook Interactif

Utiliser `analysis.ipynb` pour :

- Exploration interactive des donn√©es
- Visualisations personnalis√©es
- Tests de diff√©rents param√®tres
- Analyses ad-hoc par action

---

## üîë Points Forts du Syst√®me

### ‚úÖ **Near Real-Time Logic**

- Traitement **jour par jour** (pas de fuite future)
- Fen√™tres glissantes pour les features
- Alertes g√©n√©r√©es **en fin de s√©ance**

### ‚úÖ **Approche Hybride**

- **ML** : Isolation Forest (d√©tection non supervis√©e)
- **R√®gles m√©tier** : Expertise domaine
- **Relationnel** : Analyse de corr√©lations (mini-GNN)

### ‚úÖ **Production-Ready**

- Code modulaire et testable
- Configuration centralis√©e
- Logging complet
- CLI ergonomique

### ‚úÖ **Explicabilit√©**

- Chaque alerte est **justifi√©e**
- Types d'anomalies **cat√©goris√©s**
- Scores et m√©triques transparents

---

## üìà M√©triques de Performance

| M√©trique              | Valeur Typique              |
| --------------------- | --------------------------- |
| Taux de d√©tection     | ~5-10% (ajustable)          |
| Pr√©cision des alertes | R√®gles m√©tier + ML combin√©s |
| Temps d'ex√©cution     | <2 min pour dataset complet |
| Features calcul√©es    | 13+ indicateurs             |
| Corr√©lations          | Rolling 30 jours            |

---

## üîÆ Roadmap & Am√©liorations

### Phase 2 : Contextualisation

- ‚ú® Int√©gration **API news financi√®res**
- ‚ú® Association anomalies ‚Üí √©v√©nements (r√©sultats, annonces)

### Phase 3 : Production Avanc√©e

- ‚ú® Pipeline **Airflow** (orchestration)
- ‚ú® Dashboard **Streamlit** temps r√©el
- ‚ú® Notifications **email/Slack**

### Phase 4 : Advanced ML

- ‚ú® **Graph Neural Networks** complets (PyTorch Geometric)
- ‚ú® **Autoencoders** pour d√©tection
- ‚ú® **LSTM** pour s√©ries temporelles

### Phase 5 : Feedback Loop

- ‚ú® Scoring des faux positifs
- ‚ú® R√©entra√Ænement adaptatif
- ‚ú® A/B testing des seuils

---

## üìö Stack Technique

| Composant            | Technologie                     |
| -------------------- | ------------------------------- |
| **Data Processing**  | Pandas, NumPy                   |
| **Machine Learning** | Scikit-learn (Isolation Forest) |
| **Visualization**    | Matplotlib, Seaborn             |
| **Logging**          | Python logging                  |
| **Configuration**    | Dataclasses                     |
| **Future**           | PyTorch Geometric, Streamlit    |

---

## üèÜ Points d'Excellence

### 1. ‚úÖ **Architecture Professionnelle**

- S√©paration des responsabilit√©s (SOLID)
- Code r√©utilisable et maintenable
- Configuration centralis√©e

### 2. ‚úÖ **Rigueur Scientifique**

- Pas de fuite d'information (no data leakage)
- Fen√™tres rolling correctement impl√©ment√©es
- Validation et gestion d'erreurs

### 3. ‚úÖ **Vision Syst√©mique**

- Analyse **individuelle** (par action)
- Analyse **relationnelle** (entre actions)
- Approche **multi-couches**

### 4. ‚úÖ **R√©sultats Actionnables**

- Alertes expliqu√©es et cat√©goris√©es
- Exports pr√™ts pour d√©cision
- Visualisations claires

---

## üö¶ Workflow Recommand√©

### Pour Exploration / Pr√©sentation

```bash
jupyter notebook analysis.ipynb
```

‚Üí Interface interactive, visualisations inline

### Pour Production / Automatisation

```bash
python main.py
```

‚Üí Pipeline complet, logs, exports CSV

### Pour D√©veloppement / Debug

```python
# Dans un script Python
from src import *
from config import config

# Tester un module sp√©cifique
detector = AnomalyDetector(...)
results = detector.fit_transform(df)
```

---

## üìß Support & Contact

Pour questions ou am√©liorations :

- üìÅ Ouvrir une issue
- üìß Contacter l'√©quipe BVMT Anomaly Detection

---

## üìÑ License

MIT License - Voir `LICENSE` pour d√©tails

---

<div align="center">

**üöÄ Pr√™t √† d√©tecter les anomalies du march√© BVMT ! üöÄ**

_Near Real-Time Market Surveillance at Daily Resolution_

</div>

---

## üìÅ Structure des Donn√©es

**Fichier source** : `Data/histo_cotation_2025.csv`

**Colonnes importantes** :

- `SEANCE` : Date de la s√©ance
- `CODE` : Ticker de l'action
- `VALEUR` : Nom de l'entreprise
- `OUVERTURE`, `CLOTURE`, `PLUS_BAS`, `PLUS_HAUT` : Prix
- `QUANTITE_NEGOCIEE` : Volume
- `NB_TRANSACTION` : Nombre de transactions
- `CAPITAUX` : Capital √©chang√©

---

## üß© Pipeline du Module

### **√âtape 1 : Data Loading**

- Charger les donn√©es CSV
- Nettoyer et convertir les types
- Explorer la qualit√© des donn√©es
- **Conserver les jours √† volume nul** (signal d'illiquidit√©)

### **√âtape 2 : Feature Engineering**

Cr√©er les indicateurs cl√©s :

- `daily_return` = (Close - Open) / Open
- `range_ratio` = (High - Low) / Close
- `volume_zscore` : Z-score du volume (rolling 30j)
- `capital_zscore` : Z-score du capital (rolling 30j)
- `transaction_intensity` = Volume / (Nb_transactions + 1)
- `volatility` : √âcart-type des returns (rolling 20j)
- `deviation_from_ma` : √âcart au prix moyen mobile (20j)
- **Flags** : `flag_no_volume`, `flag_no_transactions`, `flag_no_trading`

### **√âtape 3 : Anomaly Detection**

#### **A. Machine Learning (Isolation Forest)**

- Un mod√®le **par action** (respecte les sp√©cificit√©s)
- Contamination : 5% (ajustable)
- Score d'anomalie : plus √©lev√© = plus suspect

#### **B. R√®gles M√©tier**

- ‚ö†Ô∏è **Variation extr√™me** : |daily_return| > 10%
- üìà **Pic de volume** : volume_zscore > 3
- üö´ **Pas d'activit√©** : nb_transactions = 0
- üìä **Haute volatilit√©** : volatility > 5%

### **√âtape 4 : Relational Layer (Mini-GNN)**

- Calculer les **corr√©lations rolling** entre actions (sur daily_return)
- D√©tecter les **divergences** : action avec corr√©lation moyenne < 0.3
- Identifier les comportements **isol√©s** ou **d√©synchronis√©s**

### **√âtape 5 : Alerting System**

Pour chaque anomalie d√©tect√©e :

- **Type d'alerte** : EXTREME_RETURN, VOLUME_SPIKE, NO_ACTIVITY, DIVERGENT, etc.
- **Score d'anomalie** : intensit√© de l'anomalie
- **Justification** : explication textuelle (features d√©clench√©es)
- **Export CSV** : rapport complet pr√™t pour analyse

### **√âtape 6 : Visualization**

- üìÖ **Timeline** des anomalies par jour
- üî• **Heatmap** des corr√©lations (top actions)
- üìà **Analyse d√©taill√©e** par action (prix, volume, returns, anomalies)
- üìä **Distribution** des scores et types d'alertes

---

## üì§ Outputs

Le module g√©n√®re 2 fichiers CSV :

1. **`market_anomalies_report.csv`**
   - Uniquement les anomalies d√©tect√©es
   - Colonnes : date, ticker, nom, prix, volume, score, type d'alerte, justification

2. **`market_data_with_features.csv`**
   - Dataset complet avec toutes les features calcul√©es
   - Utile pour analyses approfondies

---

## üîë Points Cl√©s

### ‚úÖ **Near Real-Time Logic**

- Traitement **jour par jour** (pas de fuite d'information future)
- Fen√™tres glissantes pour les features
- Alertes g√©n√©r√©es **√† la fin de chaque s√©ance**

### ‚úÖ **Pas de HFT**

- R√©solution **journali√®re** (pas de haute fr√©quence)
- Focus sur les **comportements anormaux**, pas le trading rapide

### ‚úÖ **Multi-Layers**

- **Individuel** : anomalies par action (ML + r√®gles)
- **Relationnel** : divergences entre actions (corr√©lations)

### ‚úÖ **Explicabilit√©**

- Chaque alerte est **justifi√©e** (features responsables)
- Types d'anomalies **cat√©goris√©s**

---

## üéØ Metrics de Succ√®s

1. **Taux de d√©tection** : ~5-10% d'anomalies (ajustable)
2. **Pertinence** : Anomalies coh√©rentes avec √©v√©nements r√©els
3. **Explicabilit√©** : Justifications claires et actionnables
4. **Performance** : Traitement rapide (<1min pour le dataset complet)

---

## üîÆ Am√©liorations Futures

### **Phase 2 : Contextualisation**

- Int√©grer des **news financi√®res** (API)
- Associer anomalies ‚Üí √©v√©nements (ex: r√©sultats trimestriels, annonces)

### **Phase 3 : Production**

- Pipeline automatis√© (Airflow / cron)
- Dashboard temps r√©el (Streamlit / Dash)
- Notifications (email / Slack)

### **Phase 4 : Advanced ML**

- Vrais **Graph Neural Networks** (PyTorch Geometric)
- **Autoencoders** pour d√©tection d'anomalies
- **LSTM** pour s√©ries temporelles

### **Phase 5 : Feedback Loop**

- Scoring des faux positifs
- R√©entra√Ænement adaptatif
- A/B testing des seuils

---

## üìö Stack Technique

- **Data Processing** : Pandas, NumPy
- **ML** : Scikit-learn (Isolation Forest)
- **Visualization** : Matplotlib, Seaborn
- **Future** : PyTorch Geometric (GNN), Streamlit (dashboard)
